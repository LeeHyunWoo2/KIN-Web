## ⛔ 이슈 2 : 데이터 동기화 로직 최적화

### 📝상황 설명

- 클라이언트가 서버와 데이터를 동기화할 때, **여러 개의 개별 API 요청**(`/sync`, `/notes`, `/categories`, `/tags`)을 보냄.
- 이로 인해 네트워크 비용이 증가하고, 동기화 과정이 비효율적이었음.
- 대량 데이터를 관리하는 과정에서 **PouchDB의 데이터 누적 문제**가 발생하여 클라이언트의 메모리 사용량이 증가.
- `forceReload` 플래그를 사용하여 **모든 데이터를 강제 초기화**하는 기능이 필요했으나, 기존 로직에서는 이를 고려하지 않았음.

---

### 🔍 원인 분석

1. **불필요한 다중 API 요청**
 - 노트, 카테고리, 태그 데이터를 각각 개별 요청하여 서버와의 통신 횟수가 많아짐.
 - 동일한 데이터를 여러 번 요청하는 중복 문제가 발생.
2. **비효율적인 데이터 저장 방식**
 - 기존에는 개별 데이터 요청을 통해 PouchDB에 저장했으나, PouchDB의 정크 데이터 증가 문제 발생.
 - 불필요한 데이터가 지속적으로 쌓이면서 로컬 저장소의 메모리 사용량이 급격히 증가.
3. **강제 초기화 기능 미흡**
 - `forceReload` 기능이 존재하지 않아, 전체 데이터를 동기화할 때 과거 데이터가 남아 있는 문제가 발생.
 - 기존 데이터를 유지한 채 동기화할 것인지, 완전히 초기화할 것인지 선택하는 기능이 필요.

---

### 🛠️ 해결 방안

1. **통합 API 추가 (`/sync/all`)**
 - 기존의 `/sync`, `/notes`, `/categories`, `/tags` API를 하나로 통합.
 - 한 번의 요청으로 노트, 카테고리, 태그 데이터를 병렬로 가져오도록 구현.
2. **클라이언트 동기화 로직 개선**
 - `forceReload` 여부에 따라 동작을 나누어, 필요한 경우 PouchDB를 완전 초기화.
 - 서버의 `lastActivity` 시간과 클라이언트의 마지막 활동 시간을 비교하여 차이가 있을 때만 동기화.
3. **PouchDB 데이터 정리 로직 추가**
 - 강제 초기화 시, PouchDB 데이터를 완전히 삭제(`destroy()`)한 후 새로운 데이터를 저장하도록 변경.
 - 불필요한 데이터 누적 문제를 해결하고, 클라이언트의 성능을 최적화.

---

### 구현 코드

### 1. 서버 구현 (`/sync/all` API 추가)

```jsx filename="syncController.js" {7-11} copy
// 통합 데이터 반환
exports.syncAllController = async (req, res) => {
  try {
    const userId = req.user.id;

    // 데이터 동시 조회
    const [notes, categories, tags] = await Promise.all([
      getNotes(userId),
      getCategories(userId),
      getTags(userId),
    ]);

    res.json({notes, categories, tags});
  } catch (error) {
    const { statusCode, message }
        = createErrorResponse(error.status || 500, error.message || "데이터를 가져오는 중 오류가 발생했습니다.");
    res.status(statusCode).json({ message });
  }
};

```

### 2. 클라이언트 구현 (`checkAndSyncOnFirstLoad` 함수 개선)

```js filename="syncAPIService.js" copy
export async function checkAndSyncOnFirstLoad(forceReload = false) {
  let db = await initDB();
  try {
    if (forceReload) {
      await db.destroy(); // 기존 데이터베이스 제거
      db = await initDB(); // 새 데이터베이스 초기화

      // forceReload가 활성화된 경우 통합 API 호출
      const response = await apiClient.get("/sync/all"); // 통합된 데이터 요청
      const { notes, categories, tags } = response.data;

      // 복원
      const decompressedNotes = notes.map((note) => ({
        ...note,
        content: getDecompressor(note.mode)(note.content),
      }))

      // 서버 데이터를 로컬 DB에 저장
      await saveDataToLocalDB("note", decompressedNotes, db);
      await saveDataToLocalDB("category", categories, db);
      await saveDataToLocalDB("tag", tags, db);

      return { decompressedNotes, categories, tags }; // 동기화된 데이터 반환
    } else {
      // forceReload가 false라면 개별 요청

      // 1. 활동 시간을 비교하기 위해 서버 API 호출
      const syncResponse = await apiClient.get("/sync");
      const convertedServerLastActivity = new Date(syncResponse.data.lastActivity).getTime();
      const clientLastActivity = await getClientLastActivity(db);

      // 2. 서버 시간과 클라이언트 마지막 활동 시간 비교
      if (convertedServerLastActivity > clientLastActivity) {
        // 새로운 데이터 요청 (3개의 개별 API 요청)
        const [notes, categories, tags] = await Promise.all([
          getNotes(true),
          getCategories(true),
          getTags(true)
        ]);

        // 로컬 데이터 업데이트
        await saveDataToLocalDB("note", notes, db);
        await saveDataToLocalDB("category", categories, db);
        await saveDataToLocalDB("tag", tags, db);

        return { notes, categories, tags }; // 동기화된 데이터 반환
      }

      // 3. 동기화 필요 없을 시 null 반환
      return null;
    }
  } catch (error) {
    console.error(error);
    return null;
  }
}
```

---

### ✅ 결과

1. **네트워크 비용 절감**: 기존의 4개 요청을 1개로 통합하여 네트워크 부하를 줄임.
2. **동기화 로직 개선**: `forceReload` 기능을 추가하여 데이터 초기화 여부를 선택할 수 있도록 함.
3. **PouchDB 데이터 최적화**: 불필요한 정크 데이터 삭제 및 메모리 사용량 감소.
4. **확장성 증가**: 새로운 동기화 방식 도입으로 이후 기능 확장에 용이한 구조가 됨.

---

### 💡 배운 점

- **API 요청을 줄이는 것이 성능 최적화에 매우 중요함**.
- **데이터베이스(특히 PouchDB) 관리는 지속적인 정리가 필요**하며, 필요 없는 데이터를 방치하면 성능이 저하됨.
- **클라이언트와 서버의 동기화 로직을 개선하면, 사용자 경험(UX)이 훨씬 좋아짐**.